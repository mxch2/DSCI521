{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module submission header\n",
    "### Submission preparation instructions \n",
    "_Completion of this header is mandatory, subject to a 2-point deduction to the assignment._ Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. You must fill out all group member Names and Drexel email addresses in the below markdown list, under header __Module submission group__. It is required to fill out descriptive notes pertaining to any tutoring support received in the completion of this submission under the __Additional submission comments__ section at the bottom of the header. If no tutoring support was received, leave NA in place. You may as well list other optional comments pertaining to the submission at bottom. _Any distruption of this header's formatting will make your group liable to the 2-point deduction._\n",
    "\n",
    "### Module submission group\n",
    "- Group member 1\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "- Group member 2\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "- Group member 3\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "- Group member 4\n",
    "    - Name: NA\n",
    "    - Email: NA\n",
    "\n",
    "### Additional submission comments\n",
    "- Tutoring support received: NA\n",
    "- Other (other): NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment group 2: Network and exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module B _(64 pts)_ Data Visualization and Interpretation\n",
    "We have two goals for this exercise:\n",
    "    \n",
    "1. Summarization through measures of commonality, centrality, variation, association, and regularity.\n",
    "2. Visualization through succicnt and intuitive representations that allow you to see all of the data.\n",
    "    \n",
    "The dataset we will be using is Philly's employees salary Dataset:\n",
    "\n",
    "- https://www.opendataphilly.org/dataset/employee-salaries-overtime/resource/e97432a2-a6a7-466e-9025-32a1da4b14e5\n",
    "\n",
    "also packaged in the assignment's data directory for conveniience:\n",
    "\n",
    "```\n",
    "./data/employee_salaries.csv\n",
    "```\n",
    "\n",
    "We will be using some native `pandas` and `matplotlib` to summarize and visualize the dataset. Some of the questions expect you to review the lecture notes. There are also some new methods and techniques introduced in this Module. Please feel free to be creative when answering the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on hypothesis generation\n",
    "We'll start looking at univariate distribution of the columns to understand what is in our dataset, and eventually use biavariate and multivariate analysis to explore existing hypotheses. However, in some instances it's the new hypotheses that arise from these visualizations that are the most insightful!\n",
    "\n",
    "So, as you answer the questions and create visualizations, please make a note any hypotheses or conclusions you can draw from your observations. These visualization methods not only help you understand what is in your data, but also become initial insights in determining the existing relationships that exist between attributes in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B1.__ _(2 pts)_ To start, load the dataset with `pandas` into a dataframe and print its `.head()` and `tail()`. Do the lines output make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B2.__ _(3 pts)_ Determine and print the number of years represented by the dataset, the number of unique departments, and the number of titles that exist across the dataset. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B3.__ _(2 pts)_ For this assignment, we will restrict to five departments with some of the highest number of employees, but they should be more or less of the same scale to get started. Since the Police Department has three times as many as the other top 6 departments, we'll ignore them (the Police) for now. In particular, determine which the _top 6_ are, print out their number os employees, and store the top 2&ndash;6 in `list` called `departments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B4.__ _(3 pts)_ Next, restrict the data to just those rows corresponding to the departments determined in __B3__ and exhibit how the data have been restricted to just these.\n",
    "\n",
    "[Hint. use your `departments` to create a boolean mask for the rows.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B5.__ _(5 pts)_ For our analysis, it may be interesting to have knowledge of employee gender, but these data are not a part of those distributed. So, download the `gender_guesser` module using your package manager of choice, e.g.:\n",
    "```\n",
    ">>> pip install gender_guesser\n",
    "```\n",
    "This module predicts gender based on first name&mdash;read up more about this package (see https://pypi.org/project/gender-guesser/), it can be very useful for feature engineering!\n",
    "\n",
    "Once you've accessed the package's contents, initialize the `gender_guesser.detector.Detector()` class for case insensitivity (`case_sensitive=False`), and apply the resulting instance's `.get_gender()` method to the `'first_name'` column of the assignment data and combine the `'male'` with `'mostly male'` and `'female'` with the `'mostly female'` output in a new column called `'gender'`.\n",
    "\n",
    "When this is all complete, print the percentage of the dataset now labeled `'male'` and `'female'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B6.__ _(2 pts)_ Here, your job is to calculate the distribution of qaurters, i.e., the percentge of the remaining data that fall into the four different values held by the `quarter` column. You should be able to answer if each value actually makes up a 'quarter' of the data?\n",
    "\n",
    "\\[Hint. You can take a quick look at the distribution by using `.value_counts()` method. This could also be helpful for part __B4__!\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B7.__ _(7 pts)_ Now, write a function called `barplot(df, column, title, top = 5)`, designed to take a `column` name from the dataframe `df` corresponding to a _categorical_ variable, like `'department'`. This function should create a bar plot for the specified `column`. Make sure your graphs have the proper axis labels and `title` considering of the specified `column`.\n",
    "\n",
    "__Important.__ The `top` argument specifies the number of `top` ocurring categories to display on the bar plot. This makes it possible to select how much of the distribution to observe!\n",
    "\n",
    "When this is complete, exhibit your functions output on the various categorical columns in the dataset, but don't try and apply it to a numeric column!\n",
    "\n",
    "\\[Hint. Use the dataframe `.value_counts()` and `.head()` methods for convenience!\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B8.__ _(5 pts)_ Here, we'll do the same thing but now for histograms and the numeric columns. In particular, write a function called `histogram(df, column, title)`, designed to take a `column` name from the dataframe `df` corresponding to a _numeric_ variable, like `'annual_salary'`. This function should create a histogram for the specified `column`. Make sure your graphs have the proper axis labels and `title` considering of the specified `column`.\n",
    "\n",
    "When this is complete, exhibit your functions output on the various numeric columns in the dataset, but don't try and apply it to a categorical column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B9.__ _(2 pts)_ Next up, let's investigate the annual salaries column. Specifically, let's look at a boxplot of this column using `matplotlib.pyplot.plot.boxplot`, as in the Chapter 3 notes. When you apply this function to the salary column describe what you see for outliers in the response box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B10.__ _(3 pts)_ Now that we can see the outliers, use the `np.percentile()` function and boolean masks to identify which employees have _high_ outlier salaries. Supposing $IQR$ refers to the size of the interquartile range of this column, utilize the boxplot visualization's criterion for 'outlier':\n",
    "\n",
    "- Outlier: a point that falls $1.5$ times an $IQR$ distance _above_ the 3rd quartile.\n",
    "\n",
    "When this is complete, use this boolean mask on our dataframe to print the `.head()` of our outlier employees and see what they do and earn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B11.__ (5 pts) Now that we've got a sense of the outliers, let's see if we can up our visualization game. Both the boxplot and histogram provide different information on the structure of the distribution of salaries. It would be great if we could compare these! However, the best comparison will occur if the box is rotated and placed below the histogram so that the location of box, whiskers, etc. falls along (parallel to) the x-axis of the histogram.\n",
    "\n",
    "In particular, use the `ax = fig.add_subplot(num_rows, num_cols, panel_number)` method on a figure object (the output of `plt.figure()`) to create different axes for the boxplot and histogram, taking care to label axes as needed. Don't forget that your boxplot should be displayed sideways and appear below the histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B12.__ _(5 pts)_ Notice that while we know how much the employees earned in gross overtime, it's not entirely clear which individuals have actually _worked_ the most overtime hours. According to [a government guideline](https://www.opm.gov/policy-data-oversight/pay-leave/pay-administration/fact-sheets/computing-hourly-rates-of-pay-using-the-2087-hour-divisor/):\n",
    "\n",
    "> Hourly rates of basic pay are computed by dividing an employee's annual rate of basic pay by 2087 hours.\n",
    "\n",
    "So, using the assumption that overtime hours are payed out at $1.5$ times an employee's annual salary, compute the number of overtime hours worked by each employee in the dataset and store this in the dataframe under a new column called `'ytd_overtime_gross_hours'`. Be sure to handle remove any NAs or Infs from the result!\n",
    "\n",
    "When this is complete, print the `.head(25)` of your resulting dataframe, sorted by this new column in descending order. In the response box below answer the following questions:\n",
    "\n",
    "- Do you think is calculation is generally correct?\n",
    "- What issues could occur with this overtime hours calculation?\n",
    "- Do you think all employees are 'full time'?\n",
    "\n",
    "\\[Hint. Assuming these individuals _do_ work full time hours, how many overtime hours _could_ an individual _actually_ work in a year?\\] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B13.__ _(5 pts)_ Our overall interest may be to understand the `'annual_salaries'` column, and one avenue towards understanding this variable is through exploration of relationships with the others. So here's one question we might ask:\n",
    "        \n",
    "- Do employees who work overtime have higher salaries? If so how much?\n",
    "\n",
    "To approach this question, compute and print the correlation between these columns and display a scatter plot. Be sure to accomadate for density in the picture as you interpret. Again, label the axes clearly and provide a title for to support readers. \n",
    "\n",
    "When this is complete, discuss any relationship that you see (or don't) between the columns in the response box below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B14.__ _(5 pts)_ Now let's explore another hypothesis&mdash;that gender affects to pay. It will be good to  compare similarly-sized groups, so first group the rows by both `'gender'` and `'title'` to observe the gender ratios. \n",
    "\n",
    "In particular, use the `.groupby(column_list)` method to create generator of grouped rows. Using the `column_list = ['gender', 'title']` argument will allow extraction of two groups (one for each gender) with a matching `'title'`. Chose one of the top 10 `'title'`s (by greatest number of employees), but make sure there is a _reasonable balance_ of males and females for the profession you choose. Store these two resulting groups from as the `males` and `females` dataframes, print the `.head()` of each. In the response box below state the `'title'` that you chose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B15.__ (2 pts) determine if there is a difference between your male and female salaries on average and discuss the severity of this difference in the response box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B16.__ (3 pts) That's a lot of work still to compare two means, and there's a lot of different titles to compare. Grouping `'gender'` against a single other `'title'` is just a comparison of `'gender'` against a single `'title'` category, as opposed to the generalization of comparing `'gender'` across _all_ of the categories in the `'title'` column for the `'annual_salary'` value. It turns out, `pandas` has some very convenient utility for this with the `pd.crosstab()` function:\n",
    "\n",
    "- ```pd.crosstab(x, y,  values=z, aggfunc = ['mean', 'std', 'count'])```\n",
    "\n",
    "Here, `x` and `y` will be our two categorical columns to compare, while `z` will be the the numeric column along whose values we wish to observe effects (of the categories). \n",
    "\n",
    "Your job is to now apply the `pd.crosstab()` function to the `'title'` and `'gender'` columns (`x` and `y`) with `'annual_salary'` for `values`. The `aggfunc` argument specifies a list of metrics to apply as summary for the columns. For in this assignment, we're just going to use the mean and standard deviation and count (number of rows in the group).\n",
    "\n",
    "After you run the `pd.crosstab()` function store the resulting dataframe as `avg_salary_gender_v_title`, and prinit/interpret the `.head(25)` in the response box below. Do you see an `'title'`s that you think are worth investigating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B17.__ (3 pts) Finally, your job here is to explore the of the 25 `'title'`s with largest difference in average pay between genders using `avg_salary_gender_v_title` dataframe.\n",
    "\n",
    "To start, drop any rows/`'title'`s for which there are NAs. Then, compute an additional columns called `'absolute_difference'`, containinig the absolute value of the differences between the male and female columns. Next, `.sort(ascending = False)` the modified `avg_salary_gender_v_title` dataframe by the new `'absolute_difference'` column and store the resultinig `.head(25)` as `top_25` and print the result.\n",
    "\n",
    "When this is done, discuss in the response box below an observations about these most widely varying salaries averages? Does the standard deviation help to glean any other information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B18.__ _(2 pts)_ Finally, take your `top_25` largest-difference `'title'`s and display them using a side-by-side barplot. To conveniently do this, we can use the `.plot(kind = 'bar')` on our `['mean']` column in the `top_25` data frame. \n",
    "\n",
    "Use the dataframe `.plot()` method, since this `pandas` method for a barplot is really just wrapping `matplotlib`'s `pyplot`. This means we can use `pyplot`/`matpltlib` (proper) commands for many things like the `plt.title()`, but to make the figure size nice we have the pass the `figsize=(x_inches,y_inches)` argument to the dataframe `.plot()` method. So, as is necessary make this visualization look nice to ease your discussion (above)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
